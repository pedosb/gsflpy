\documentclass[a4paper,10pt]{article}

\usepackage[brazilian]{babel}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}


%opening
\title{}
\author{}

\begin{document}

%\maketitle

%\begin{abstract}

%\end{abstract}

%\section{}

Proposta: An Heterogeneous and Plastic Front-end. \\

Etapas:

\begin{enumerate}
 \item Utilizar o HVite (ferramenta do HTK) para gerar lattices com score acústico (likelihood) frame-a-frame.
 \item Confusion detection:
    \begin{itemize}
    \item Construir classificadores binários, ou seja, capazes de detectar se há ou não confusão. Esses classificadores serão treinados usando o WEKA e durante a fase de teste (quando não sabemos qual é a transcrição correta) devem identificar pontos com alta confusabilidade.
    \item Construir classificadores de confusão capazes de definir e identificar $S$ situações de confusabilidade. Por exemplo, visualizar grande concorrência entre um determinado número de fones. \\
    Seria possível encaixar essa observação em alguma característica linguística: consoantes fricativas, vozeadas?
    \end{itemize}
 \item Score detection:
    \begin{itemize}
    \item Construir classificadores de correcção (feature selection) para encontrar as features de entrada (MFCC, PLP, etc.) para treinar $S$ classificadores. Daí que vem a ideia de heterogeneidade.\\ Mas não ficou claro como treinar esses classificadores:\\
    Como associar confusão entre fones à uma determinada feature?\\
    Como encontrar a melhor feature para um dado classificador $S$?
    \end{itemize}
\end{enumerate}


Nomenclatura:\\

Estamos trabalhando a base \textbf{digits16k}. Foram utilizados 22 fones, retirados do dicionário fonético do TIMIT,
mais o modelo de silêncio com HMM's com 3 estados utilizando a estrutura \textit{left-to-right}.
O modelo \textit{short-pause} com apenas um estado emissor (\textit{tee-model}) foi construído através da cópia do estado central do modelo de silêncio.
Assim, o fone $f$ no estado $s$ será representado pelo modelo $f_{s}$. No total serão 67 modelos.\\

Todo arquivo de áudio (.wav) terá seu arquivo MFCC (.mfc) correspondente. Esse arquivo é composto por um vetor $\bar{x}$ ($N$ x 39),
onde $N$ é o número de frames da sentença. Assim, o iésimo coeficiente do vetor MFCC no frame $t$ será representado por $\bar{x}_{i}(t)$.\\

A margem $M$ é determinada pela diferença entre os scores acústicos de duas sentenças da lattice em um determinado frame.
Por exemplo, a Equação~\ref{eq:margem} calcula a margem entre a sentença reconhecida (melhor concorrente) e outra sentença concorrente dentro de uma lattice.

\begin{equation}
\label{eq:margem}
M(t) = b_{q^{*}_{i}}^{f_{s}}(t) - b_{q_{i}}^{f_{s}}(t)
\end{equation}
onde $b_{q_{i}}^{f_{s}}(t)$ representa o score acústico que a sentença $q_{i}$ apresenta no frame $t$ com o modelo $f_{s}$.\\


Trabalhando com o HTK:\\

O HTK 3.3 não permite utilizar os parâmetros -f e -n juntos. O
executável \emph{hviter.exe} gera scores acústicos frame-a-frame no
campo \emph{d} da lattice. Para isso, alterações no código foram
feitas: arquivo \emph{HRecer.c}. Esse executável roda sem o
parâmetro -f e o campo \emph{d} não é preenchido em todos os
links. A versão HTK 3.4 não traz melhoria com relação as lattices.
As mesmas alterações feitas na versão 3.3 foram replicadas na versão 3.4, contudo não surtiram efeito.

Já a última versão HTK 3.4.1 traz melhoria com relação as lattices.
Uma delas é a flag PHNALG que permite utilizar os parâmetros -f e -n
juntos. O código do \emph{HRec.c} foi alterado para gerar os scores
frame-a-frame. Todos os links possuem o campo \emph{d}. Contudo, o
último frame de alguns links apresentam erro no valor do score
acústico, ou seja, valores muito discrepantes. Esses links são
aqueles que não apareciam nas versões anteriores.\\


Trabalhando com o WEKA:\\

Vamos trabalhar com os 1.956 arquivos que apresentaram erro de
reconhecimento e sempre com duas sequências fornecidas pela sua
lattice: a correta (de acordo com a transcrição) e a melhor
concorrente (ou reconhecida). Caso a sequência correta não esteja
presente na lattice, aplicar forced-alignment.

\begin{itemize}

 \item A ferramenta \textit{gsfl} foi implementada para gerar o grafo das lattices.

 \item Usando a opção -n i [N] N-best recognition (using textit{i} tokens) da ferramenta \textit{HVite} com \textit{i}
igual a 3 (três) obteve-se um subconjunto com 1.649 arquivos que possuem a transcrição correta como uma das sequências
fornecidas pela sua lattice.

 \item Na tentativa de aumentar a quantidade de arquivos, o parâmetro \textit{i} foi incrementado para 4 (quatro),
porém o \textit{gsfl} não conseguiu tratar as lattices resultantes.

 \item Foi adicionada a opção -c na ferramenta \textit{gsfl}. Assim, todas as lattices que apresentaram erro de
reconhecimento foram lidas buscando-se a sentença que foi reconhecida (maior score acústico acumulado) e a sentença que
deveria ter sido reconhecida (opção -c). Os arquivos resultantes foram salvos no diretório /path.
\newline
\end{itemize}


Arquivo Arff:\\

Serão coletadas duas bases de dados. A primeira base de dados foi construída com os 1.649 arquivos que apresentaram erro de reconhecimento.
Por escolha, as 15 (quinze) melhores concorrentes foram selecionadas dentro de cada lattice, porém apenas
duas sentenças foram consideradas para determinar as regiões de confusão: a de maior score acústico acumulado (sentença reconhecida)
e a que deveria ter sido reconhecida (sentença correta).

A intenção é buscar regiões de confusão, ou seja, intervalos de tempo onde as duas sentenças divergem com relação ao score acústico.
Para compor o arquivo Arff apenas o ponto (frame) que apresentar a maior margem positiva (Equação~\ref{eq:margem}) dentro de cada região de confusão será considerado.

Exemplo numérico: Cada linha da matriz $H$ (15 x $N$) abaixo representa uma das
sentenças concorrentes com o seu respectivo score acústico
frame-a-frame. Para exemplificar, apenas a primeira e segunda linhas
serão representadas. A primeira linha da matriz $H$ é composta pelo
score acústico (likelihood) frame-a-frame da sentença reconhecida.
A segunda linha é composta pelo score acústico frame-a-frame da sentença correta.\\

$H = \begin{bmatrix} -80&-80&-100&-120&-90&-80&-80&-50&-60&-100
                  \\ -80&-80&-120&-70&-130&-80&-80&-70&-90&-100
                  \\  ...&...&...&...&...&...&...&...&...&... \end{bmatrix}$\\

Em seguida, a matriz $H$ é normalizada em função do maior score acústico em cada frame:\\

$\bar{H} = \begin{bmatrix} 0& 0& 0&   -50& 0&  0& 0& 0&   0& 0
                        \\ 0& 0& -20&  0& -40& 0& 0& -20& -30& 0
                  \\  ...&...&...&...&...&...&...&...&...&...  \end{bmatrix}$\\

Foram identificadas duas regiões de confusão na matriz $\bar{H}$. A primeira entre os frames 3-5 e a segunda entre os frames 8-9.
Assim, a matriz $\bar{H}$ contribui com dois exemplos para o arquivo Arff: os frames 5 e 9, onde ocorre a maior margem positiva
da primeira e da segunda região de confusão, respectivamente.

Já a segunda base de dados foi construída com arquivos que foram corretamente reconhecidos.
Por escolha, as 15 (quinze) melhores concorrentes foram selecionadas dentro de cada lattice.
A sentença de maior score acústico acumulado (sentença correta e reconhecida) foi comparada com as demais 14 concorrentes, individualmente,
para determinação das regiões de confusão. Novamente, para compor o arquivo Arff apenas o ponto (frame) que apresentar a maior margem
positiva dentro de cada região de confusão identificada será considerado.\\

Considerações sobre a construção do arquivo Arff:

\begin{itemize}

 \item O ponto de maior margem não pode corresponder ao mesmo modelo nas duas sentenças analisadas.
Nesse caso será escolhido o ponto consecutivo dentro da região de confusão que possua modelos diferentes, seguindo a ordem decrescente da margem.

 \item Os atributos (features) serão os 67 modelos mais uma classe binária que identifica se há ou não confusão naquele frame.
Lembrando que é conhecido o modelo (HMM) onde cada uma das 15 (quinze) sentenças se encontra frame-a-frame.

 \item Caso o mesmo modelo apareça em duas os mais sentenças, será escolhido o de maior score acústico.

 \item Quando um dos modelos, que são os atributos do arquivo Arff, não é encontrado em nenhuma das 15 (quinze) sentenças analisadas, 
seu valor é preenchido com 1 (um).

 \item Uma região de confusão não pode se repetir dentro da mesma lattice. Esse fato acontece muito na segunda base de dados, onde duas concorrentes, quando
comparadas com a sentença correta, apresentam a mesma região de confusão. Entende-se por regiões de confusão iguais aquelas que estão situadas 
no mesmo intervalo de tempo, ou seja, iniciam no mesmo frame e possuem o mesmo tamanho.

\end{itemize}

Abaixo segue o conteúdo de um arquivo Arff:

\begin{verbatim}
@attribute iy1[3] numeric
@attribute w[2] numeric
@attribute uw1[3] numeric
@attribute v[4] numeric
@attribute s[2] numeric
@attribute ao1[3] numeric
@attribute ow2[3] numeric
@attribute ey1[4] numeric
@attribute s[4] numeric
@attribute v[2] numeric
@attribute k[3] numeric
@attribute n[3] numeric
@attribute ay1[3] numeric
@attribute eh1[3] numeric
@attribute k[2] numeric
@attribute ax[2] numeric
@attribute z[3] numeric
@attribute r[3] numeric
@attribute sil[2] numeric
@attribute eh1[4] numeric
@attribute ow1[4] numeric
@attribute th[3] numeric
@attribute ey1[2] numeric
@attribute t[2] numeric
@attribute eh1[2] numeric
@attribute sp[2] numeric
@attribute sil[4] numeric
@attribute w[4] numeric
@attribute ey1[3] numeric
@attribute ih1[3] numeric
@attribute t[4] numeric
@attribute ow1[2] numeric
@attribute ao1[2] numeric
@attribute f[2] numeric
@attribute iy1[2] numeric
@attribute ah1[4] numeric
@attribute s[3] numeric
@attribute uw1[4] numeric
@attribute ay1[4] numeric
@attribute n[4] numeric
@attribute uw1[2] numeric
@attribute ah1[3] numeric
@attribute ow2[2] numeric
@attribute v[3] numeric
@attribute ao1[4] numeric
@attribute z[4] numeric
@attribute n[2] numeric
@attribute ay1[2] numeric
@attribute w[3] numeric
@attribute z[2] numeric
@attribute ax[3] numeric
@attribute r[4] numeric
@attribute ow2[4] numeric
@attribute r[2] numeric
@attribute ax[4] numeric
@attribute ih1[2] numeric
@attribute t[3] numeric
@attribute ih1[4] numeric
@attribute th[2] numeric
@attribute sil[3] numeric
@attribute ah1[2] numeric
@attribute iy1[4] numeric
@attribute f[3] numeric
@attribute f[4] numeric
@attribute k[4] numeric
@attribute ow1[3] numeric
@attribute th[4] numeric
@attribute conf {0,1}

@data
1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,-12.94,1,1,1,1,1,...,0
1,1,1,1,1,1,1,1,1,1,1,1,1,-3.61,1,1,1,1,1,1,-2.41,1,1,1,1,0,1,...,1
1,1,1,-21.2,1,1,1,1,0,1,1,1,1,1,1,1,1,-3.47,-16.97,1,1,1,1,1,1,...,0
1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,-17.93,1,1,1,1,1,1,-24.13,1,...,1
1,1,-136.94,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,-8.01,1,1,1,1,,1,...,0
1,0,1,1,1,1,1,1,1,1,1,1,-4.43,1,1,1,1,1,1,1,1,-33.93,-3.97,1,1,...,0
1,1,1,1,1,1,-33.16,1,1,0,1,1,1,1,1,1,-16.53,1,1,1,1,1,1,1,1,1,1,...,1
1,1,0,1,1,1,1,1,1,1,-14.13,1,1,1,1,1,1,1,-11.78,1,1,1,1,1,1,1,1,...,1

\end{verbatim}
 


% número total de estados. Total de 69 estados.
% $N$: número de frames na sequência.
% $A(t)$: conjunto de estados ativos no frame $t$.
% $b_{j}(t)$: score acústico do estado $j$ no frame $t$.\\
% Exemplo numérico:
% $A(t)$ = \{2,9,38,5\}
% Score acústico dos estados ativos: $b_{j}(t)$ = \{-60,-30,-120,-40\}
% Em seguida, normalizar fazendo o maior ser zero: $b_{j}(t)$ = \{-30,0,-90,-10\}
% Definir o score acústico dos estados não-ativos: $b_{j}(t)$ = min - threshold
% Fazendo threshold = 100, tem-se: $b_{j}(t)$ = -190
% Entrada no WEKA para o frame $t$: -190,-30,-190,-190,-10,...,-190,sim/não\\
% A última coluna é uma classe binária que informa se nesse frame o fonema/estado com maior score faz parte ou não da sequência correta.\\
% Problema que pode surgir com tamanho dos arquivos: usar representação esparsa. O WEKA tem essa facilidade.\\
% Dúvida que se pretende responder: como um classificador (SVM, clustering) se comporta nessa situação?


\end{document}
